{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import utils\n",
    "from sklearn.metrics.pairwise import paired_distances\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import plotnine as pn\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity, paired_distances\n",
    "from sklearn.preprocessing import StandardScaler, scale\n",
    "from scipy.spatial import distance\n",
    "\n",
    "from einops import rearrange, reduce, repeat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(utils)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjs = utils.ExpInfo.getSubjIDs()\n",
    "task = utils.ExpInfo.taskName[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wSize = 60\n",
    "\n",
    "def group(subj):\n",
    "    df_beh = utils.LoadData.behaviorData(subj, task)\n",
    "    # _, h, _ = utils.LoadData.xhy(subj, task, wSize=wSize)\n",
    "    # _, h_disp, _ = utils.LoadData.xhy_disp(subj, task, wSize=wSize)\n",
    "    h, h_disp = utils.LoadData.mouseMovement_array(subj, task, velocity=True, packDot=True)\n",
    "    dist_measure = 'cosine'\n",
    "\n",
    "    # dist_timeSeries = []\n",
    "    # v_timeSeries = []\n",
    "    d = []\n",
    "    for iTrial in range(len(h)):\n",
    "        h_trial = h[iTrial]\n",
    "        h_disp_trial = h_disp[iTrial]\n",
    "\n",
    "        # hidden action plan velocity\n",
    "        vh = np.diff(h_trial, axis=0)\n",
    "        vh_disp_dot = np.diff(h_disp_trial, axis=0)\n",
    "\n",
    "        dist_timeSeries_ = paired_distances(h_trial, h_disp_trial, metric=dist_measure)\n",
    "        v_timeSeries_ = paired_distances(vh, vh_disp_dot, metric=dist_measure)\n",
    "        \n",
    "        d.append({'dist_mean': dist_timeSeries_.mean(), \n",
    "                  'dist_sd': dist_timeSeries_.std(),\n",
    "                  'v_mean': v_timeSeries_.mean(),\n",
    "                  'v_sd': v_timeSeries_.std()})\n",
    "        \n",
    "        # change  distance to \"similarity\" index\n",
    "        # d.append({'dist_mean': 1-dist_timeSeries_.mean(), \n",
    "        #         'dist_sd': 1-dist_timeSeries_.std(),\n",
    "        #         'v_mean': 1-v_timeSeries_.mean(),\n",
    "        #         'v_sd': 1-v_timeSeries_.std()})    \n",
    "        \n",
    "    df_ = pd.concat([df_beh, pd.DataFrame(d)], axis=1)\n",
    "    X = df_[['dist_mean', 'v_mean']]\n",
    "    # X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    y = df_['response']\n",
    "    LR = LogisticRegression(fit_intercept=True, class_weight='balanced').fit(X, y)\n",
    "    df_['response_pred'] = LR.predict(X)\n",
    "    coef_ = LR.coef_\n",
    "    df_['b1'] = coef_[0][0]\n",
    "    df_['b2'] = coef_[0][1]\n",
    "    df_['b0'] = LR.intercept_[0]\n",
    "\n",
    "    # standardise the data\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    y = df_['response']\n",
    "    LR = LogisticRegression(fit_intercept=True, class_weight='balanced').fit(X, y)\n",
    "    df_['response_pred_stdz'] = LR.predict(X)\n",
    "    coef_ = LR.coef_\n",
    "    df_['b1_stdz'] = coef_[0][0]\n",
    "    df_['b2_stdz'] = coef_[0][1]\n",
    "    df_['b0_stdz'] = LR.intercept_[0]\n",
    "        \n",
    "        \n",
    "    # Only use action plan position\n",
    "    # X = StandardScaler().fit_transform(X)\n",
    "    X = df_[['dist_mean']]\n",
    "    y = df_['response']\n",
    "    LR = LogisticRegression(fit_intercept=True, class_weight='balanced').fit(X, y)\n",
    "    df_['response_pred_p_only'] = LR.predict(X)\n",
    "    coef_ = LR.coef_\n",
    "    df_['b1_stdz_p_only'] = coef_[0][0]\n",
    "    # df_['b2_stdz'] = coef_[0][1]\n",
    "    df_['b0_stdz_p_only'] = LR.intercept_[0]\n",
    "                \n",
    "    return df_\n",
    "\n",
    "df = utils.GroupOperation.map(group, subjs)\n",
    "df = pd.concat(df, axis=0)\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = utils.Save.savepath('ana_one_dot_predicting_individual_beh_profile_cossmilarity', 'prediction.csv')\n",
    "df.to_csv(fn, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df.copy()\n",
    "df_ = df_[['participant', 'actual control', 'angular bias', 'response_pred', 'group']]\n",
    "df_ = df_.groupby(['participant', 'actual control', 'angular bias', 'group']).mean()\n",
    "df_ = df_.reset_index()\n",
    "\n",
    "grid = sns.FacetGrid(col='participant', col_wrap=5, data=df_)\n",
    "grid.map_dataframe(sns.pointplot, \n",
    "                   x='actual control', \n",
    "                   y='response_pred', \n",
    "                   hue='angular bias')\n",
    "grid.add_legend()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "sns.catplot(x='actual control', y='response_pred', hue='angular bias', data=df_, col='group', kind='point')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df[['participant', 'group', 'b0', 'b1', 'b2', 'mu']].groupby(['participant', 'group']).mean()\n",
    "df_ = df_.reset_index()\n",
    "df_.plot()\n",
    "df_.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation with reaching noise-free performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically nothing happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ctrl = [utils.LoadData.behaviorData(subj, utils.ExpInfo.taskName[2]) for subj in subjs]\n",
    "df_ctrl = pd.concat(df_ctrl, axis=0)\n",
    "df_ctrl = df_ctrl.query('`actual control`==1')[['participant', 'group', 'number of reaching']]\n",
    "df_ctrl = df_ctrl.groupby(['participant', 'group']).mean().reset_index()\n",
    "df_m = df_.merge(df_ctrl, on=['participant', 'group'])\n",
    "df_m['mu'] = -(df_m['b0'] / df_m['b1'])\n",
    "df_m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_m.corr())\n",
    "\n",
    "# compute stats \n",
    "import pingouin as pg\n",
    "print(pg.corr(df_m['b0'], df_m['b1'], method='pearson'))\n",
    "print(pg.corr(df_m['b0'], df_m['b2'], method='pearson'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='b0', y='b1', data=df_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='b0', y='b1', data=df_m, hue='group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set figure size\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.barplot(x='participant', y='mu', data=df_m, hue='group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj = subjs[46]\n",
    "df_beh = utils.LoadData.behaviorData(subj, task)\n",
    "\n",
    "df_ = pd.concat([df_beh, pd.DataFrame(d)], axis=1)\n",
    "X = df_[['dist_mean']]\n",
    "X = df_[['v_mean']]\n",
    "X = df_[['dist_mean', 'v_mean']]\n",
    "# X = df_[['dist_mean', 'v_mean', 'dist_sd', 'v_sd']]\n",
    "# X = df_[['dist_mean']]\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "y = df_['response']\n",
    "# class_weightdict = {0: 1, 1: 1}\n",
    "LR = LogisticRegression(fit_intercept=True, class_weight='balanced').fit(X, y)\n",
    "df_['response_pred'] = LR.predict(X)\n",
    "print(LR.coef_, LR.intercept_)\n",
    "\n",
    "plt.figure()\n",
    "sns.pointplot(x='actual control', y='response_pred', hue='angular bias', data=df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_ = pd.DataFrame(d)\n",
    "df_ = pd.concat([df_beh, d_], axis=1)   \n",
    "# df_['dist_mean']=1-df_['dist_mean']\n",
    "plt.figure()\n",
    "sns.pointplot(x='actual control', y='dist_mean', hue='angular bias', data=df_)\n",
    "plt.figure()\n",
    "sns.pointplot(x='actual control', y='v_mean', hue='angular bias', data=df_)\n",
    "plt.figure()\n",
    "sns.pointplot(x='actual control', y='dist_sd', hue='angular bias', data=df_)\n",
    "plt.figure()\n",
    "sns.pointplot(x='actual control', y='v_sd', hue='angular bias', data=df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 2\n",
    "# mean = np.zeros(n)\n",
    "# cov = np.eye(n)\n",
    "# rv = multivariate_normal(mean=mean, cov=cov)\n",
    "# samples = rv.rvs(10000)\n",
    "\n",
    "# dist_sample = distance.cdist(np.expand_dims(mean, 0), samples, 'euclidean').flatten()\n",
    "# sns.distplot(dist_sample)\n",
    "# # plt.plot(samples[:, 0], samples[:, 1], 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_separability_all(h_trial, h_disp_trial):\n",
    "    \"\"\"\n",
    "    Compute the binary separability of the given dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    from sklearn.cluster import KMeans\n",
    "    from sklearn.mixture import GaussianMixture\n",
    "    # hidden action plan velocity\n",
    "    vh = np.diff(h_trial, axis=0)\n",
    "    vh_disp = np.diff(h_disp_trial, axis=0)\n",
    "\n",
    "    Xs = {}\n",
    "\n",
    "    X = np.vstack([h_trial, h_disp_trial])\n",
    "    Xs['p'] = X\n",
    "    X = np.vstack([vh, vh_disp])\n",
    "    Xs['v'] = X\n",
    "\n",
    "\n",
    "    hvh = np.hstack([h_trial[:-1], vh])\n",
    "    hvh_disp = np.hstack([h_disp_trial[:-1], vh_disp])\n",
    "    X = np.vstack([hvh, hvh_disp])\n",
    "    Xs['p+v'] = X\n",
    "\n",
    "\n",
    "    diff = h_disp_trial - h_trial\n",
    "    diff_zero = np.zeros_like(diff)\n",
    "    X = np.vstack([diff, diff_zero])\n",
    "    Xs['p_diff'] = X\n",
    "\n",
    "\n",
    "    diff = vh_disp - vh\n",
    "    diff_zero = np.zeros_like(diff)\n",
    "    X = np.vstack([diff, diff_zero])\n",
    "    Xs['v_diff'] = X\n",
    "\n",
    "    diff1 = h_disp_trial - h_trial\n",
    "    diff2 = vh_disp - vh\n",
    "    diff = np.hstack([diff1[:-1, :], diff2])\n",
    "    diff_zero = np.zeros_like(diff)\n",
    "    X = np.vstack([diff, diff_zero])\n",
    "    Xs['p_diff+v_diff'] = X\n",
    "\n",
    "    def binary_separability(X, nRun=10):\n",
    "        labels = np.tile(np.array([0, 1]), [int(X.shape[0]/2), 1]).flatten(order='F')\n",
    "        \n",
    "        acc_run = []\n",
    "        for iRun in range(nRun):\n",
    "            # labels_ = KMeans(n_clusters=2, random_state=4).fit_predict(X)\n",
    "            labels_ = GaussianMixture(n_components=2, random_state=iRun).fit_predict(X)\n",
    "            \n",
    "            acc = np.mean(labels_ == labels)\n",
    "            if acc < 0.5:\n",
    "                acc = 1-acc\n",
    "            acc_run.append(acc)\n",
    "        acc_run = np.array(acc_run).mean()\n",
    "        return -acc\n",
    "\n",
    "    for name, X in Xs.items():\n",
    "        # print(name, binary_separability(X))\n",
    "        Xs[name] = binary_separability(X)\n",
    "    return Xs\n",
    "\n",
    "# binary_separability_all(h_trial, h_disp_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subj = subjs[5]\n",
    "# iTrial = 0\n",
    "wSize = 60\n",
    "\n",
    "\n",
    "df_beh = utils.LoadData.behaviorData(subj, task)\n",
    "_, h, _ = utils.LoadData.xhy(subj, task, wSize=wSize)\n",
    "_, h_disp, _ = utils.LoadData.xhy_disp(subj, task, wSize=wSize)\n",
    "dist_measure = 'euclidean'\n",
    "\n",
    "# dist_timeSeries = []\n",
    "# v_timeSeries = []\n",
    "d = []\n",
    "bs = []\n",
    "for iTrial in range(len(h)):\n",
    "    h_trial = h[iTrial][:-1, :]\n",
    "    h_disp_trial = h_disp[iTrial]\n",
    "\n",
    "    # hidden action plan velocity\n",
    "    vh = np.diff(h_trial, axis=0)\n",
    "    vh_disp_dot = np.diff(h_disp_trial, axis=0)\n",
    "\n",
    "    dist_timeSeries_ = paired_distances(h_trial, h_disp_trial, metric=dist_measure)\n",
    "    v_timeSeries_ = paired_distances(vh, vh_disp_dot, metric=dist_measure)\n",
    "    \n",
    "    d.append({'dist_mean': 1-dist_timeSeries_.mean(), \n",
    "              'dist_sd': -dist_timeSeries_.std(),\n",
    "              'v_mean': 1-v_timeSeries_.mean(),\n",
    "              'v_sd': -v_timeSeries_.std()})\n",
    "    \n",
    "    \n",
    "    \n",
    "    bs.append(binary_separability_all(h_trial, h_disp_trial))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = pd.concat([df_beh, pd.DataFrame(d), pd.DataFrame(bs)], axis=1)\n",
    "columns = df_.loc[:, 'dist_mean':].columns.values\n",
    "for column in columns:\n",
    "    plt.figure()\n",
    "    sns.pointplot(x='actual control', y=column, hue='angular bias', data=df_)\n",
    "    plt.title(column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ = pd.concat([df_beh, pd.DataFrame(d)], axis=1)\n",
    "# X = df_[['p']]\n",
    "# X = df_[['v']]\n",
    "# X = df_[['p', 'v']]\n",
    "X = df_[['p+v']]\n",
    "X = df_[['p', 'v', 'p+v']]\n",
    "# X = df_[['p_diff', 'v_diff']]\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "y = df_['response']\n",
    "LR = LogisticRegression(fit_intercept=True, class_weight='balanced').fit(X, y)\n",
    "df_['response_pred'] = LR.predict(X)\n",
    "print(LR.coef_, LR.intercept_)\n",
    "\n",
    "plt.figure()\n",
    "sns.pointplot(x='actual control', y='response_pred', hue='angular bias', data=df_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# By trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subj = subjs[10]\n",
    "# # iTrial = 0\n",
    "# wSize = 60\n",
    "\n",
    "\n",
    "# df_beh = utils.LoadData.behaviorData(subj, task)\n",
    "# _, h, _ = utils.LoadData.xhy(subj, task, wSize=wSize)\n",
    "# _, h_disp, _ = utils.LoadData.xhy_disp(subj, task, wSize=wSize)\n",
    "# dist_measure = 'euclidean'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iTrial = 5\n",
    "# h_trial = h[iTrial][:-1, :]\n",
    "# h_disp_trial = h_disp[iTrial]\n",
    "\n",
    "# # hidden action plan velocity\n",
    "# vh = np.diff(h_trial, axis=0)\n",
    "# vh_disp = np.diff(h_disp_trial, axis=0)\n",
    "\n",
    "# dist_timeSeries_ = paired_distances(h_trial, h_disp_trial, metric=dist_measure)\n",
    "# v_timeSeries_ = paired_distances(vh, vh_disp, metric=dist_measure)\n",
    "\n",
    "# # d.append({'dist_mean': 1-dist_timeSeries_.mean(), \n",
    "# #             'dist_sd': -dist_timeSeries_.std(),\n",
    "# #             'v_mean': 1-v_timeSeries_.mean(),\n",
    "# #             'v_sd': -v_timeSeries_.std()})\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_beh.iloc[iTrial])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "# from sklearn.mixture import GaussianMixture\n",
    "# Xs = {}\n",
    "\n",
    "# X = np.vstack([h_trial, h_disp_trial])\n",
    "# Xs['position'] = X\n",
    "# X = np.vstack([vh, vh_disp])\n",
    "# Xs['velocity'] = X\n",
    "\n",
    "\n",
    "# hvh = np.hstack([h_trial[:-1], vh])\n",
    "# hvh_disp = np.hstack([h_disp_trial[:-1], vh_disp])\n",
    "# X = np.vstack([hvh, hvh_disp])\n",
    "# Xs['p+v'] = X\n",
    "\n",
    "\n",
    "# diff = h_disp_trial - h_trial\n",
    "# diff_zero = np.zeros_like(diff)\n",
    "# X = np.vstack([diff, diff_zero])\n",
    "# Xs['p_diff'] = X\n",
    "\n",
    "\n",
    "# diff = vh_disp - vh\n",
    "# diff_zero = np.zeros_like(diff)\n",
    "# X = np.vstack([diff, diff_zero])\n",
    "# Xs['v_diff'] = X\n",
    "\n",
    "# diff1 = h_disp_trial - h_trial\n",
    "# diff2 = vh_disp - vh\n",
    "# diff = np.hstack([diff1[:-1, :], diff2])\n",
    "# diff_zero = np.zeros_like(diff)\n",
    "# X = np.vstack([diff, diff_zero])\n",
    "# Xs['p_diff+v_diff'] = X\n",
    "\n",
    "# def binary_separability(X, nRun=10):\n",
    "#     labels = np.tile(np.array([0, 1]), [int(X.shape[0]/2), 1]).flatten(order='F')\n",
    "    \n",
    "#     acc_run = []\n",
    "#     for iRun in range(nRun):\n",
    "#         # labels_ = KMeans(n_clusters=2, random_state=4).fit_predict(X)\n",
    "#         labels_ = GaussianMixture(n_components=2, random_state=0).fit_predict(X)\n",
    "        \n",
    "#         acc = np.mean(labels_ == labels)\n",
    "#         if acc < 0.5:\n",
    "#             acc = 1-acc\n",
    "#         acc_run.append(acc)\n",
    "#     acc_run = np.array(acc_run).mean()\n",
    "#     return acc\n",
    "\n",
    "# for name, X in Xs.items():\n",
    "#     print(name, binary_separability(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(10, 5))\n",
    "# ax.plot(dist_timeSeries_)\n",
    "# ax.set_ylim([0, 2])\n",
    "# plt.title('position dist')\n",
    "\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(10, 5))\n",
    "# ax.plot(v_timeSeries_)\n",
    "# ax.set_ylim([0, 2])\n",
    "# plt.title('v dist')\n",
    "\n",
    "\n",
    "# # intention traj diff\n",
    "\n",
    "# dd = utils.DataProcessing.diff(h_trial)\n",
    "# fig, ax = plt.subplots(figsize=(10, 5))\n",
    "# ax.plot(dd)\n",
    "# ax.set_ylim([0, 2])\n",
    "# plt.title('intention t t+1')\n",
    "\n",
    "# dd = utils.DataProcessing.diff(h_disp_trial)\n",
    "# fig, ax = plt.subplots(figsize=(10, 5))\n",
    "# ax.plot(dd)\n",
    "# ax.set_ylim([0, 2])\n",
    "# plt.title('disp t t+1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff = h_disp_trial - h_trial\n",
    "# mean = np.mean(diff, axis=0)\n",
    "# cov = np.cov(diff, rowvar=0)\n",
    "\n",
    "# from scipy.stats import multivariate_normal\n",
    "# rv = multivariate_normal(mean=mean, cov=cov)\n",
    "# nSample = 10000\n",
    "# samples = rv.rvs(nSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.spatial import distance\n",
    "# dist_sample = distance.cdist(np.expand_dims(mean, 0), samples, 'euclidean').flatten()\n",
    "# # dist_sample = paired_distances(np.tile(mean, (nSample, 1)), samples, metric='euclidean')\n",
    "# dist_target = distance.cdist(np.expand_dims(mean, 0), np.zeros((1, diff.shape[1])), 'euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(dist_sample)\n",
    "# plt.plot(dist_target, 'or')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 2\n",
    "# mean = np.zeros(n)\n",
    "# cov = np.eye(n)\n",
    "# rv = multivariate_normal(mean=mean, cov=cov)\n",
    "# samples = rv.rvs(10000)\n",
    "\n",
    "# dist_sample = distance.cdist(np.expand_dims(mean, 0), samples, 'euclidean').flatten()\n",
    "# sns.distplot(dist_sample)\n",
    "# # plt.plot(samples[:, 0], samples[:, 1], 'o')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0bfe45cfa5af8caecc1324233dd1bb80b7f37bc486d77a1e494b9aae421ca5f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
