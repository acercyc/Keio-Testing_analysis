{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import utils \n",
    "import torch\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trialno</th>\n",
       "      <th>frameCounter</th>\n",
       "      <th>x-shift</th>\n",
       "      <th>y-shift</th>\n",
       "      <th>dot-x</th>\n",
       "      <th>dot-y</th>\n",
       "      <th>group</th>\n",
       "      <th>subjID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-15.2</td>\n",
       "      <td>24.4</td>\n",
       "      <td>934.096038</td>\n",
       "      <td>527.534657</td>\n",
       "      <td>S</td>\n",
       "      <td>K-Reg-S-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>933.121802</td>\n",
       "      <td>526.959450</td>\n",
       "      <td>S</td>\n",
       "      <td>K-Reg-S-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>933.039034</td>\n",
       "      <td>526.568106</td>\n",
       "      <td>S</td>\n",
       "      <td>K-Reg-S-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.952638</td>\n",
       "      <td>526.177548</td>\n",
       "      <td>S</td>\n",
       "      <td>K-Reg-S-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.857495</td>\n",
       "      <td>525.789028</td>\n",
       "      <td>S</td>\n",
       "      <td>K-Reg-S-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trialno  frameCounter  x-shift  y-shift       dot-x       dot-y group  \\\n",
       "0      1.0           1.0    -15.2     24.4  934.096038  527.534657     S   \n",
       "1      1.0           2.0     -0.8      0.8  933.121802  526.959450     S   \n",
       "2      1.0           3.0     -0.4      0.0  933.039034  526.568106     S   \n",
       "3      1.0           4.0     -0.4      0.0  932.952638  526.177548     S   \n",
       "4      1.0           5.0     -0.4      0.0  932.857495  525.789028     S   \n",
       "\n",
       "       subjID  \n",
       "0  K-Reg-S-18  \n",
       "1  K-Reg-S-18  \n",
       "2  K-Reg-S-18  \n",
       "3  K-Reg-S-18  \n",
       "4  K-Reg-S-18  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjID = 'K-Reg-S-18'\n",
    "task = 'one_dot'\n",
    "df = utils.load_mouseMovement(subjID, task)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trialno</th>\n",
       "      <th>x-shift</th>\n",
       "      <th>y-shift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.008000</td>\n",
       "      <td>0.012842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.000421</td>\n",
       "      <td>0.000421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.000211</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.000211</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.000211</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trialno   x-shift   y-shift\n",
       "0      1.0 -0.008000  0.012842\n",
       "1      1.0 -0.000421  0.000421\n",
       "2      1.0 -0.000211  0.000000\n",
       "3      1.0 -0.000211  0.000000\n",
       "4      1.0 -0.000211  0.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "screenSise = utils.getScreenSise(df)\n",
    "df_ = df[['trialno', 'x-shift', 'y-shift']].copy()\n",
    "df_['x-shift'] /= screenSise\n",
    "df_['y-shift'] /= screenSise\n",
    "df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nValidTrials = 6\n",
    "\n",
    "trials = set(df_['trialno'])\n",
    "trials_val = np.random.choice(list(trials), nValidTrials)\n",
    "trial_train = trials.difference(trials_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wSize = int(1.2 * 60)\n",
    "interval = 1\n",
    "\n",
    "d_train = []\n",
    "d_val = []\n",
    "for iTrial in set(df_['trialno']):\n",
    "    d_ = df_.query(f'trialno == {iTrial}')\n",
    "    d_ = d_.drop(columns='trialno').values\n",
    "    d_ = utils.rollingWindow(d_, wSize, interval)\n",
    "    if iTrial in trial_train:\n",
    "        d_train.append(d_)\n",
    "    else:\n",
    "        d_val.append(d_)\n",
    "\n",
    "d_train = np.concatenate(d_train, axis=0)\n",
    "d_val = np.concatenate(d_val, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, d):\n",
    "        self.d = d\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.d.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.d[idx]\n",
    "\n",
    "dataset_train = TrajDataset(d_train)\n",
    "dataset_val = TrajDataset(d_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajNet(nn.Module):\n",
    "    def __init__(self, nHidden=8, nFeature=16, nhead=4, dim_feedforward=64, num_layers=4, dropout=0.1):\n",
    "        super(TrajNet, self).__init__()\n",
    "        \n",
    "        self.nHidden = nHidden\n",
    "        self.nFeature = nFeature\n",
    "\n",
    "        # encoder\n",
    "        self.conv_enc = nn.Conv1d(2, nFeature, 1)\n",
    "        encoder_ = nn.TransformerEncoderLayer(d_model=nFeature,\n",
    "                                              nhead=nhead,\n",
    "                                              dim_feedforward=dim_feedforward,\n",
    "                                              batch_first=True, \n",
    "                                              activation='gelu',\n",
    "                                              dropout=dropout)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_, num_layers=num_layers)\n",
    "\n",
    "        # hidden bottleneck\n",
    "        self.hidden = nn.Linear(nFeature, nHidden)\n",
    "        self.memory = nn.Linear(nHidden, nHidden * nFeature)\n",
    "\n",
    "        # decoder\n",
    "        self.conv_dec1 = nn.Conv1d(2, nFeature, 1)    \n",
    "        decoder_ = nn.TransformerDecoderLayer(d_model=nFeature, \n",
    "                                              nhead=nhead, \n",
    "                                              dim_feedforward=dim_feedforward, \n",
    "                                              batch_first=True, \n",
    "                                              activation='gelu',\n",
    "                                              dropout=dropout)\n",
    "        self.decoder = nn.TransformerDecoder(decoder_, num_layers=num_layers)\n",
    "        generator_ = nn.TransformerEncoderLayer(d_model=nFeature, \n",
    "                                                nhead=nhead, \n",
    "                                                dim_feedforward=dim_feedforward, \n",
    "                                                batch_first=True, \n",
    "                                                activation='gelu',\n",
    "                                                dropout=dropout)        \n",
    "        self.generator = nn.TransformerEncoder(generator_, num_layers=num_layers)\n",
    "        self.conv_dec2 = nn.Conv1d(nFeature, 2, 1)\n",
    "        \n",
    "        # output\n",
    "        # self.output = nn.Linear(nFeature, 2)        \n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        # src.shape = (batch_size, nSrc, nFeature=2)\n",
    "        # tgt.shape = (batch_size, nTgt, nFeature=2)\n",
    "        \n",
    "        # ---------------------------------------------------------------------------- #\n",
    "        #                                   encoding                                   #\n",
    "        # ---------------------------------------------------------------------------- #\n",
    "        nBatch = src.shape[0]\n",
    "        nTime = src.shape[1]\n",
    "        x = src\n",
    "        \n",
    "        # expend feature dimension\n",
    "        #   x_expand = (batch, time, nFeature)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.conv_enc(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        x = self.encoder(x)\n",
    "        x = torch.tanh(x)\n",
    "\n",
    "        # extract hidden control units\n",
    "        #   x.shape = (batch, head)\n",
    "        x = x[:, 0, :]\n",
    "        hidden = self.hidden(x)\n",
    "        y = torch.tanh(hidden)\n",
    "\n",
    "        # construct output embedding\n",
    "        memory = self.memory(y)\n",
    "        memory = memory.reshape(nBatch, self.nHidden, self.nFeature)\n",
    "        \n",
    "        # ---------------------------------------------------------------------------- #\n",
    "        #                                   decoding                                   #\n",
    "        # ---------------------------------------------------------------------------- #\n",
    "        # # decode control command\n",
    "        y = tgt.permute(0, 2, 1)\n",
    "        y = self.conv_dec1(y)\n",
    "        y = y.permute(0, 2, 1)\n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt.shape[1]).to(device)\n",
    "        y = self.decoder(y, memory, tgt_mask=tgt_mask)\n",
    "\n",
    "        # # generate motor sequence\n",
    "        # #   y.shape = (batch_size, nTime, nFeature=2)\n",
    "        # src_mask = nn.Transformer.generate_square_subsequent_mask(y.shape[1]).to(device)\n",
    "        # y = self.generator(y, mask=src_mask)\n",
    "        y = y.permute(0, 2, 1)\n",
    "        y = self.conv_dec2(y)\n",
    "        y = y.permute(0, 2, 1)\n",
    "        return y\n",
    "    \n",
    "    def autoRegressiveDecoding(self, src, nTime):\n",
    "        tgt = torch.zeros((src.shape[0], 1, 2)).to(device).float()\n",
    "        for i in range(nTime):\n",
    "            y = self.forward(src, tgt)[:, -1:, :]\n",
    "            tgt = torch.concat((tgt, y), dim=1)\n",
    "        return tgt\n",
    "    \n",
    "# model = TrajNet().to(device)\n",
    "# # y = model(torch.rand(4, 3, 2))\n",
    "# y = model(torch.rand(4, 3, 2).to(device), torch.rand(4, 4, 2).to(device))\n",
    "# y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "model = TrajNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, running_loss: 3.086700063559152e-05\n",
      "epoch:1, running_loss: 3.1481736139952414e-05\n",
      "epoch:2, running_loss: 3.156864272803188e-05\n",
      "epoch:3, running_loss: 3.075204411513753e-05\n",
      "epoch:4, running_loss: 3.122811898551329e-05\n",
      "epoch:5, running_loss: 3.098993471850036e-05\n",
      "epoch:6, running_loss: 3.13524639759916e-05\n",
      "epoch:7, running_loss: 3.0865800224476225e-05\n",
      "epoch:8, running_loss: 3.081824833475601e-05\n",
      "epoch:9, running_loss: 3.092597904169546e-05\n",
      "epoch:10, running_loss: 3.2712403227969374e-05\n",
      "epoch:11, running_loss: 3.096789685552028e-05\n",
      "epoch:12, running_loss: 3.1752775106087e-05\n",
      "epoch:13, running_loss: 3.142090553382397e-05\n",
      "epoch:14, running_loss: 3.1345154817132684e-05\n",
      "epoch:15, running_loss: 3.0717182883179084e-05\n",
      "epoch:16, running_loss: 3.126566242048584e-05\n",
      "epoch:17, running_loss: 3.094824420334111e-05\n",
      "epoch:18, running_loss: 3.090351125963222e-05\n",
      "epoch:19, running_loss: 3.244661116489802e-05\n",
      "epoch:20, running_loss: 3.179961261115956e-05\n",
      "epoch:21, running_loss: 3.074184024092002e-05\n",
      "epoch:22, running_loss: 3.0603098483757985e-05\n",
      "epoch:23, running_loss: 3.092125959867808e-05\n",
      "epoch:24, running_loss: 3.0816425435462864e-05\n",
      "epoch:25, running_loss: 3.149788293383833e-05\n",
      "epoch:26, running_loss: 3.07169377321639e-05\n",
      "epoch:27, running_loss: 3.0967209577565226e-05\n",
      "epoch:28, running_loss: 3.0527542473942754e-05\n",
      "epoch:29, running_loss: 3.05739314762363e-05\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(30):\n",
    "    running_loss = 0.0\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x = batch.to(device).float()\n",
    "        tgt = torch.roll(x, 1, 1)\n",
    "        tgt[:, 0, :] = 0\n",
    "        tgt_ = x\n",
    "        y = model(x, tgt)\n",
    "        loss = criterion(y, tgt_)\n",
    "        loss.backward()\n",
    "        optimizer.step()        \n",
    "        running_loss += loss.item()\n",
    "        # print(f'loss: {loss.item()}')\n",
    "    print(f'epoch:{epoch}, running_loss: {running_loss/(i+1)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/acercyc/projects/Keio Testing_analysis/src/models_test_local.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Blocalhost/home/acercyc/projects/Keio%20Testing_analysis/src/models_test_local.ipynb#ch0000000vscode-remote?line=0'>1</a>\u001b[0m d \u001b[39m=\u001b[39m dataset_train[np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(dataset_train))]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blocalhost/home/acercyc/projects/Keio%20Testing_analysis/src/models_test_local.ipynb#ch0000000vscode-remote?line=1'>2</a>\u001b[0m \u001b[39m# d = dataset_val[63]\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blocalhost/home/acercyc/projects/Keio%20Testing_analysis/src/models_test_local.ipynb#ch0000000vscode-remote?line=3'>4</a>\u001b[0m fig, axs \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset_train' is not defined"
     ]
    }
   ],
   "source": [
    "d = dataset_train[np.random.randint(0, len(dataset_train))]\n",
    "# d = dataset_val[63]\n",
    "\n",
    "fig, axs = plt.subplots()\n",
    "axs.plot(0, 0, 'or')\n",
    "axs.plot(d[:, 0].cumsum(), d[:, 1].cumsum(), '-')\n",
    "axs.axis('equal')\n",
    "\n",
    "model.eval()\n",
    "src = torch.from_numpy(d).unsqueeze(0).to(device).float()\n",
    "d_ = model.forward(src, src)\n",
    "d_ = d_.detach().cpu().numpy()\n",
    "d_ = d_.squeeze()\n",
    "axs.plot(d_[:, 0].cumsum(), d_[:, 1].cumsum(), '-')\n",
    "\n",
    "d_ = model.autoRegressiveDecoding(src, src.shape[1])\n",
    "d_ = d_.detach().cpu().numpy()\n",
    "d_ = d_.squeeze()\n",
    "axs.plot(d_[:, 0].cumsum(), d_[:, 1].cumsum(), '-')\n",
    "# d_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model_test_local.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x = batch.to(device).float()\n",
    "        y = model(x)\n",
    "        loss = criterion(y, x)\n",
    "        loss.backward()\n",
    "        optimizer.step()        \n",
    "        running_loss += loss.item()\n",
    "        # print(f'loss: {loss.item()}')\n",
    "    print(f'epoch:{epoch}, running_loss: {running_loss/(i+1)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'permute'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26784/3461673869.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautoRegressiveDecoding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m72\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26784/1227933687.py\u001b[0m in \u001b[0;36mautoRegressiveDecoding\u001b[1;34m(self, src, nTime)\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[0mtgt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnTime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m             \u001b[0mtgt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtgt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26784/1227933687.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, src, tgt)\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[1;31m# expend feature dimension\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;31m#   x_expand = (batch, time, nFeature)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_enc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'permute'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_ = torch.from_numpy(d).unsqueeze(0).to(device).float()\n",
    "d_ = model.forward(d_)\n",
    "d_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dataset_train[2000]\n",
    "src = torch.from_numpy(d).unsqueeze(0).to(device).float()\n",
    "tgt = torch.zeros((1, 1, 2)).to(device).float()\n",
    "model.eval()\n",
    "optimizer.zero_grad()\n",
    "nTime = int(1.2 * 60)\n",
    "for i in range(10):\n",
    "    y = model(src, tgt)[:, -1:, :]\n",
    "    tgt = torch.concat((tgt, y), dim=1)\n",
    "tgt = tgt[:, 1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots()\n",
    "axs.plot(d[:, 0].cumsum(), d[:, 1].cumsum(), '-')\n",
    "axs.axis('equal')\n",
    "\n",
    "d_ = tgt.detach().cpu().numpy()\n",
    "d_ = d_.squeeze()\n",
    "axs.plot(d_[:, 0].cumsum(), d_[:, 1].cumsum(), '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dataset_train[2000]\n",
    "d_ = torch.from_numpy(d).unsqueeze(0).to(device).float()\n",
    "model.eval()\n",
    "# genTraj = \n",
    "i = 0\n",
    "d_ = model.forward(d_[:, i, :].unsqueeze(1), add_tgt_mask=False)\n",
    "d_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3, 4, 5]\n",
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_layer = nn.TransformerDecoderLayer(d_model=8, nhead=8)\n",
    "transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=6)\n",
    "memory = torch.rand(10, 2, 8)\n",
    "tgt = torch.rand(4, 2, 8)\n",
    "transformer_decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_mask = nn.Transformer.generate_square_subsequent_mask(4)\n",
    "out = transformer_decoder(tgt, memory, tgt_mask=tgt_mask)\n",
    "print(out[:, 0, :])\n",
    "\n",
    "out = transformer_decoder(tgt, memory)\n",
    "print(out[:, 0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    tgt_mask = nn.Transformer.generate_square_subsequent_mask(i+1)\n",
    "    if i == 0:\n",
    "        out = transformer_decoder(tgt[i, :, :].unsqueeze(0), memory, tgt_mask=tgt_mask)\n",
    "    else:\n",
    "        out = transformer_decoder(tgt[0:(i+1), :, :], memory, tgt_mask=tgt_mask)\n",
    "    # out_.append(out)\n",
    "    print(out[:, 0, :])\n",
    "    \n",
    "for i in range(4):\n",
    "    tgt_mask = nn.Transformer.generate_square_subsequent_mask(i+1)\n",
    "    if i == 0:\n",
    "        out = transformer_decoder(tgt[i, :, :].unsqueeze(0), memory, tgt_mask=None)\n",
    "    else:\n",
    "        out = transformer_decoder(tgt[0:(i+1), :, :], memory, tgt_mask=None)\n",
    "    # out_.append(out)\n",
    "    print(out[:, 0, :])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Transformer.generate_square_subsequent_mask(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_layer = nn.TransformerDecoderLayer(d_model=512, nhead=8)\n",
    "transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=6)\n",
    "# memory = torch.rand(10, 32, 512)\n",
    "# tgt = torch.rand(20, 32, 512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = transformer_decoder(tgt, memory)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajNet(nn.Module):\n",
    "    def __init__(self, nFeature=64, nhead=8, dim_feedforward=128, num_layers=4, dropout=0.1):\n",
    "        super(TrajNet, self).__init__()\n",
    "\n",
    "        # encoder\n",
    "        self.conv_enc = nn.Conv1d(2, nFeature, 1)\n",
    "        encoder_ = nn.TransformerEncoderLayer(d_model=nFeature,\n",
    "                                              nhead=nhead,\n",
    "                                              dim_feedforward=dim_feedforward,\n",
    "                                              batch_first=True, \n",
    "                                              activation='gelu',\n",
    "                                              dropout=dropout)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_, num_layers=num_layers)\n",
    "\n",
    "        # hidden bottleneck\n",
    "        self.hidden = nn.Linear(nFeature, nFeature)\n",
    "\n",
    "        # decoder\n",
    "        self.conv_dec1 = nn.Conv1d(2, nFeature, 1)        \n",
    "        decoder_ = nn.TransformerEncoderLayer(d_model=nFeature, \n",
    "                                              nhead=nhead, \n",
    "                                              dim_feedforward=dim_feedforward, \n",
    "                                              batch_first=True, \n",
    "                                              activation='gelu',\n",
    "                                              dropout=dropout)\n",
    "        self.decoder = nn.TransformerEncoder(decoder_, num_layers=num_layers)\n",
    "        generator_ = nn.TransformerEncoderLayer(d_model=nFeature, \n",
    "                                                nhead=nhead, \n",
    "                                                dim_feedforward=dim_feedforward, \n",
    "                                                batch_first=True, \n",
    "                                                activation='gelu',\n",
    "                                                dropout=dropout)        \n",
    "        self.generator = nn.TransformerEncoder(generator_, num_layers=num_layers)\n",
    "        self.conv_dec2 = nn.Conv1d(nFeature, 2, 1)\n",
    "        \n",
    "        # output\n",
    "        # self.output = nn.Linear(nFeature, 2)        \n",
    "\n",
    "    def forward(self, src):\n",
    "        # src.shape = (batch_size, nSrc, nFeature=2)\n",
    "        # tgt.shape = (batch_size, nTgt, nFeature=2)\n",
    "        \n",
    "        # ---------------------------------------------------------------------------- #\n",
    "        #                                   encoding                                   #\n",
    "        # ---------------------------------------------------------------------------- #\n",
    "        nTime = src.shape[1]\n",
    "        x = src\n",
    "        \n",
    "        # expend feature dimension\n",
    "        #   x_expand = (batch, time, nFeature)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.conv_enc(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        x = self.encoder(x)\n",
    "        x = nn.functional.gelu(x)\n",
    "\n",
    "        # extract hidden control units\n",
    "        #   x.shape = (batch, head)\n",
    "        x = x[:, 0, :]\n",
    "        hidden = self.hidden(x)\n",
    "        y = nn.functional.gelu(hidden)\n",
    "\n",
    "        # construct output embedding\n",
    "        y = torch.unsqueeze(y, 1)\n",
    "        y = y.repeat((1, nTime, 1))\n",
    "        \n",
    "        \n",
    "        # ---------------------------------------------------------------------------- #\n",
    "        #                                   decoding                                   #\n",
    "        # ---------------------------------------------------------------------------- #\n",
    "\n",
    "           \n",
    "        # decode control command\n",
    "        y = self.decoder(y)\n",
    "\n",
    "        # generate motor sequence\n",
    "        #   y.shape = (batch_size, nTime, nFeature=2)\n",
    "        src_mask = nn.Transformer.generate_square_subsequent_mask(y.shape[1]).to(device)\n",
    "        y = self.generator(y, mask=src_mask)\n",
    "        y = y.permute(0, 2, 1)\n",
    "        y = self.conv_dec2(y)\n",
    "        y = y.permute(0, 2, 1)\n",
    "        return y\n",
    "    \n",
    "    # def autoRegressiveDecoding(self, src, nTime):\n",
    "    #     tgt = torch.zeros((src.shape[0], 1, 2)).to(device).float()\n",
    "    #     for i in range(nTime):\n",
    "    #         y = self.forward(src, tgt)[:, -1:, :]\n",
    "    #         tgt = torch.concat((tgt, y), dim=1)\n",
    "    #     return tgt[:, 1:, :]\n",
    "    \n",
    "# model = TrajNet().to(device)\n",
    "# model(torch.rand(2, 3, 2).to(device).float())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8, dropout=0.1)\n",
    "transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=6)\n",
    "src = torch.rand(10, 32, 512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_encoder.eval()\n",
    "out = transformer_encoder(src)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto-encoder model\n",
    "class TrajNet(nn.Module):\n",
    "    def __init__(self, nHidden=64, nFeature=512, nhead=4, dim_feedforward=128, num_layers=4, dropout=0.1):\n",
    "        super(TrajNet, self).__init__()\n",
    "        self.nHidden = nHidden\n",
    "        self.nFeature = nFeature\n",
    "        \n",
    "        # encoding\n",
    "        self.conv_enc = nn.Conv1d(2, nFeature, 1)\n",
    "        encoder_ = nn.TransformerEncoderLayer(d_model=nFeature,\n",
    "                                              nhead=nhead,\n",
    "                                              dim_feedforward=dim_feedforward,\n",
    "                                              batch_first=True, \n",
    "                                              activation='gelu',\n",
    "                                              dropout=dropout)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_, num_layers=num_layers)   \n",
    "        \n",
    "        # hidden bottleneck\n",
    "        self.hidden = nn.Linear(nFeature, nHidden)   \n",
    "        \n",
    "        # decoding        \n",
    "        self.linear = nn.Linear(nHidden, 72 * nFeature)\n",
    "        self.conv_dec1 = nn.Conv1d(nHidden, nFeature, 1)\n",
    "        decoder_ = nn.TransformerEncoderLayer(d_model=nFeature, \n",
    "                                              nhead=nhead, \n",
    "                                              dim_feedforward=dim_feedforward, \n",
    "                                              batch_first=True, \n",
    "                                              activation='gelu',\n",
    "                                              dropout=dropout)\n",
    "        self.decoder = nn.TransformerEncoder(decoder_, num_layers=num_layers)\n",
    "        self.conv_dec2 = nn.Conv1d(nFeature, 2, 1) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        nBatch = x.shape[0]\n",
    "        nTime = x.shape[1]\n",
    "        \n",
    "        # encoding\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.conv_enc(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.encoder(x)\n",
    "        \n",
    "        # hidden bottleneck\n",
    "        x = x[:, 0, :]\n",
    "        hidden = self.hidden(x)\n",
    "        \n",
    "        \n",
    "        # decoding\n",
    "        y = self.linear(hidden)\n",
    "        y = y.reshape((nBatch, 72, self.nFeature))\n",
    "        # y = nn.functional.selu(y)\n",
    "        # y = torch.ones((nBatch, nTime, self.nHidden)).to(device)\n",
    "        # y[:, 0, :] = hidden\n",
    "        # y = y.permute(0, 2, 1)\n",
    "        # y = self.conv_dec1(y)\n",
    "        # y = y.permute(0, 2, 1)\n",
    "        # y = nn.functional.selu(y)\n",
    "        \n",
    "        y = self.decoder(y)\n",
    "        y = y.permute(0, 2, 1)\n",
    "        y = self.conv_dec2(y)\n",
    "        y = y.permute(0, 2, 1)\n",
    "        \n",
    "        \n",
    "        return y\n",
    "\n",
    "\n",
    "# x = torch.rand(3, 72, 2)\n",
    "# model = TrajNet()\n",
    "# y = model(x)\n",
    "# y.shape\n",
    "# y\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c38880c0b251f16d71f4d18036765822673f8ed835e0120528c8cebbbd5836f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
